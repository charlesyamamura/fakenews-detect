{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97966c6-bd53-4069-a5d7-cfa3630ccd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy import tokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import LsiModel, TfidfModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2ba64-4b66-487a-98dd-ceb40e453c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot options\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "default_plot_colour = \"#00bfbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043122a-c5e1-4fc2-9de3-abc85aea1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fakeNews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871af19-f1b9-4e73-ac0a-69f8e61480ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84cb53-6f56-4fc6-8aa2-865703acd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84096d6c-ba71-4408-9048-b423791bf2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fake_or_factual'].value_counts().plot(kind='bar', color=default_plot_colour)\n",
    "plt.title('Count of Article Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f8153-ec50-471d-b04b-70ba5983b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf102f59-3cdb-41e7-b2c8-6e891a293f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = data[data[\"fake_or_factual\"] == \"Fake News\"]\n",
    "fact = data[data[\"fake_or_factual\"] == \"Factual News\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e3296-3bb9-4127-a071-d32defd9cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedocs = list(nlp.pipe(fake['text']))\n",
    "factdocs = list(nlp.pipe(fact['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602967c2-62bc-44ec-a6fe-761c5646e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTokenTags(doc: spacy.tokens.doc.Doc):\n",
    "    return [(i.text, i.ent_type_, i.pos_) for i in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f49311-224e-43d5-9878-08f5995513e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "faketags = []\n",
    "columns = ['token', 'nerTag', 'posTag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2935c52-6d13-4c71-b806-0262cdb1f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, doc in enumerate(fakedocs):\n",
    "    tags = extractTokenTags(doc)\n",
    "    tags = pd.DataFrame(tags)\n",
    "    tags.columns = columns\n",
    "    faketags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff79e89-50d0-402e-ba6a-dc5dfaa663de",
   "metadata": {},
   "outputs": [],
   "source": [
    "faketags = pd.concat(faketags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19315a7-3451-468c-b606-d196ea4aa235",
   "metadata": {},
   "outputs": [],
   "source": [
    "facttags = []\n",
    "columns = ['token', 'nerTag', 'posTag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddd9d8-57e3-48b5-b884-052bab1852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, doc in enumerate(factdocs):\n",
    "    tags = extractTokenTags(doc)\n",
    "    tags = pd.DataFrame(tags)\n",
    "    tags.columns = columns\n",
    "    facttags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c1edb-da3e-40c8-9ca6-4936c27c025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "facttags = pd.concat(facttags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518771a-ffac-434b-813f-4e862cab5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "facttags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b59f50-d9ac-438b-83ee-f05a9bc44da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token frequency count (fake)\n",
    "posCountsFake = faketags.groupby(['token','posTag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "posCountsFake.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7510bbc-dc0b-48c7-80e5-8746137f644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token frequency count (fact)\n",
    "posCountsFact = facttags.groupby(['token','posTag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "posCountsFact.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040da9e-21ca-4f97-bd40-770acee6b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies of pos tags\n",
    "posCountsFake.groupby(['posTag'])['token'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4426a45-52ef-4307-8239-0e92ccf9b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "posCountsFact.groupby(['posTag'])['token'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9590ac58-2635-445c-b40c-1367402c3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "posCountsFake[posCountsFake.posTag == \"NOUN\"][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b3347-7822-448c-a0a1-13ed4d0d93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posCountsFact[posCountsFact.posTag == \"NOUN\"][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672f004-c30d-490b-8efc-78b2970ec777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top entities in fake news\n",
    "topFake = faketags[faketags['nerTag'] != \"\"] \\\n",
    "                    .groupby(['token','nerTag']).size().reset_index(name='counts') \\\n",
    "                    .sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b50807-92cd-4ae8-91bb-2e31f63a80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topFact = facttags[facttags['nerTag'] != \"\"] \\\n",
    "                    .groupby(['token','nerTag']).size().reset_index(name='counts') \\\n",
    "                    .sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e19ba7-a750-49ae-9aff-8a05a257378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom palette to ensure plots are consistent\n",
    "nerPalette = {\n",
    "    'ORG': sns.color_palette(\"Set2\").as_hex()[0],\n",
    "    'GPE': sns.color_palette(\"Set2\").as_hex()[1],\n",
    "    'NORP': sns.color_palette(\"Set2\").as_hex()[2],\n",
    "    'PERSON': sns.color_palette(\"Set2\").as_hex()[3],\n",
    "    'DATE': sns.color_palette(\"Set2\").as_hex()[4],\n",
    "    'CARDINAL': sns.color_palette(\"Set2\").as_hex()[5],\n",
    "    'PERCENT': sns.color_palette(\"Set2\").as_hex()[6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a43bcb-4d21-448c-b315-5e46e2e1360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = 'counts',\n",
    "    y = 'token',\n",
    "    hue = 'nerTag',\n",
    "    palette = nerPalette,\n",
    "    data = topFake[0:10],\n",
    "    orient = 'h',\n",
    "    dodge=False\n",
    ") \\\n",
    ".set(title='Most Common Entities in Fake News')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f54e4e-017a-407f-9bab-78ace0268f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = 'counts',\n",
    "    y = 'token',\n",
    "    hue = 'nerTag',\n",
    "    palette = nerPalette,\n",
    "    data = topFact[0:10],\n",
    "    orient = 'h',\n",
    "    dodge=False\n",
    ") \\\n",
    ".set(title='Most Common Entities in Factual News')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca67c3-57fc-4bb4-ad06-1594fcd33437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of the factual news has a location tag at the beginning of the article, let's use regex to remove this\n",
    "data['text_clean'] = data['text'].apply(lambda x: re.sub(r\"^[^-]*-\\s*\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c505de-a9e2-4ad5-84b6-f4fa8c46c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'] = data['text_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0a262-ccd6-4dd9-965c-6d4e802fc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'] = data['text_clean'].apply(lambda x: re.sub(r\"[^\\w\\s]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c890d3-9c7d-40c7-888f-1df1ecceb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55db3de-59fe-4abb-a014-9d46b5e2a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sws = stopwords.words('english')\n",
    "print(sws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9025fa-53b2-46b8-812a-8f1c3da7cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'] = data['text_clean'].apply(lambda x: \" \".join(word for word in x.split() if word not in sws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16f67d-27cf-47d4-b29d-203b3218baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6511bb-3790-445e-a72a-1afbd86c98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean'] = data['text_clean'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb8c7d-f512-4f9e-933c-80abafaa0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text_clean'] = data['text_clean'].apply(lambda tokens: [lemmatizer.lemmatize(token)\\\n",
    "                                             for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c42b6a-7fdc-413a-8363-c089eb68aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sum(data['text_clean'], [])\n",
    "unigrams = (pd.Series(nltk.ngrams(tokens, 1)).value_counts()).reset_index()[:10]\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf480ce-9c8f-4b24-b659-fe11ddc7715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams['token'] = unigrams['index'].apply(lambda x: x[0]) # extract the token from the tuple so we can plot it\n",
    "\n",
    "sns.barplot(x = \"count\", \n",
    "            y = \"token\", \n",
    "            data=unigrams,\n",
    "            orient = 'h',\n",
    "            palette=[default_plot_colour],\n",
    "            hue = \"token\", legend = False)\\\n",
    ".set(title='Most Common Unigrams After Preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8cca7-18f7-4433-853d-457b645e4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = (pd.Series(nltk.ngrams(tokens, 2)).value_counts()).reset_index()[:10]\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f22c7-4ff9-433c-8281-96f2064fceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams['token'] = bigrams['index'].apply(lambda x: x[0]) # extract the token from the tuple so we can plot it\n",
    "\n",
    "sns.barplot(x = \"count\", \n",
    "            y = \"token\", \n",
    "            data=bigrams,\n",
    "            orient = 'h',\n",
    "            palette=[default_plot_colour],\n",
    "            hue = \"token\", legend = False)\\\n",
    ".set(title='Most Common Bigrams After Preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915c25a-3fbc-4dae-bca5-682ffee57c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09699b-3344-4dd7-97a5-d9009bae25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sent_score'] = data[\"text\"].apply(lambda x: vader.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9e94d-cabe-4e91-b526-624e6ba7a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7c080-317b-4582-964a-b0e5fc2df97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "bins = [-1, -0.1, 0.1, 1]\n",
    "names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "data['sentiment'] = pd.cut(data['sent_score'], bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969136e-746e-4935-941f-36ba8c44be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'].value_counts().plot.bar(color=default_plot_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769470c5-3dd3-4d76-a146-4669987f2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    x = 'fake_or_factual',\n",
    "    hue = 'sentiment',\n",
    "    palette = sns.color_palette(\"hls\"),\n",
    "    data = data\n",
    ") \\\n",
    ".set(title='Sentiment by News Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115430f-2ad4-4a25-b980-a66f3eeb7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeNews = data[data[\"fake_or_factual\"] == \"Fake News\"][\"text_clean\"].reset_index(drop=True)\n",
    "dictFake = corpora.Dictionary(fakeNews)\n",
    "docFake = [dictFake.doc2bow(text) for text in fakeNews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf4a62-2f2c-4a47-b7ae-28e5b1d531f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate coherence scores to determine an optimum number of topics\n",
    "coherenceValues = []\n",
    "mdlLst = []\n",
    "\n",
    "minTopics = 2\n",
    "maxTopics = 11\n",
    "\n",
    "for numTopics in range(minTopics, maxTopics+1):\n",
    "    model = gensim.models.LdaModel(docFake, num_topics=numTopics, id2word = dictFake)\n",
    "    mdlLst.append(model)\n",
    "    coherenceMdl = CoherenceModel(model=model, texts=fakeNews, dictionary=dictFake, coherence='c_v')\n",
    "    coherenceValues.append(coherenceMdl.get_coherence())\n",
    "    \n",
    "plt.plot(range(minTopics, maxTopics+1), coherenceValues)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d291fd-bb06-4047-9704-e1e548e7e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lda model\n",
    "nTopics = 8 \n",
    "\n",
    "ldaMdl = gensim.models.LdaModel(corpus=docFake,\n",
    "                                       id2word=dictFake,\n",
    "                                       num_topics=nTopics)\n",
    "\n",
    "ldaMdl.print_topics(num_topics=nTopics, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6e9ea-e258-4ce3-a536-49bc1df1247c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb96357-7398-4b5c-af77-faf2ef99fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfCorpus(termMatrix):\n",
    "    # create a corpus using tfidf vectorization\n",
    "    tfidf = TfidfModel(corpus=termMatrix, normalize=True)\n",
    "    corpusTfidf = tfidf[termMatrix]\n",
    "    return corpusTfidf\n",
    "\n",
    "\n",
    "def getCoherScores(corpus, dictionary, text, minTopics, maxTopics):\n",
    "    # generate coherence scores to determine an optimum number of topics\n",
    "    coherenceValues = []  # Initialize coherenceValues here\n",
    "    mdlLst = []\n",
    "    for numTopics in range(minTopics, maxTopics + 1):\n",
    "        model = LsiModel(corpus, num_topics=numTopics, id2word=dictionary, random_seed=0)\n",
    "        mdlLst.append(model)\n",
    "        coherenceModel = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence='c_v')\n",
    "        coherenceValues.append(coherenceModel.get_coherence())\n",
    "\n",
    "    # plot results\n",
    "    plt.plot(range(minTopics, maxTopics + 1), coherenceValues)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence Score\")\n",
    "    plt.legend([\"Coherence Values\"], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create tfidf representation\n",
    "corpusTfidfFake = tfidfCorpus(docFake)\n",
    "\n",
    "# Coherence scores for fake news data\n",
    "getCoherScores(corpusTfidfFake, dictFake, fakeNews, minTopics=2, maxTopics=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5cb33-332f-4d7e-8ba9-fbed6e72fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for fake news data\n",
    "lsa = LsiModel(corpusTfidfFake, id2word=dictFake, num_topics=5)\n",
    "lsa.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bb359-278e-4781-aecf-6a9439df5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [','.join(map(str, l)) for l in data['text_clean']]\n",
    "Y = data['fake_or_factual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4c1ff-27e5-4f96-b23c-2626c485341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5241ed-1b43-4838-8807-9125bb50d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfit = countvec.fit_transform(X)\n",
    "bow = pd.DataFrame(cvfit.toarray(), columns=countvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d008c7d-3ae7-4f02-a364-582dd27ea8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(bow, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb776c2-8234-40db-a613-d2c028520d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0).fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9c595-42e9-4864-bdb5-02fb22bb5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredlr = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599ca1b-508a-4f72-b9f4-a8cb42904f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ypredlr, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af396ba-28ef-4701-bfab-b44997a0fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, ypredlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8779a25-8964-4ba3-ad54-57527e70dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier().fit(Xtrain, ytrain)\n",
    "ypredsvm = svm.predict(Xtest)\n",
    "accuracy_score(ypredsvm, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da616e-6fda-47e9-aa6b-a5cc45d6d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, ypredsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3dfe00-4cdd-4614-ae98-1a60b8761c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
